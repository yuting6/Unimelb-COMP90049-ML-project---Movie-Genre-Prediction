{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Action       0.00      0.00      0.00         6\n",
      "   Adventure       0.00      0.00      0.00         2\n",
      "   Animation       1.00      0.33      0.50         3\n",
      "    Children       0.50      0.33      0.40         3\n",
      "      Comedy       0.41      0.39      0.40        38\n",
      "       Crime       0.33      0.20      0.25         5\n",
      " Documentary       0.65      0.61      0.63        18\n",
      "       Drama       0.49      0.51      0.50        43\n",
      "     Fantasy       0.35      0.33      0.34        18\n",
      "   Film_Noir       0.00      0.00      0.00         4\n",
      "      Horror       0.36      0.50      0.42         8\n",
      "     Musical       0.20      0.10      0.13        10\n",
      "     Mystery       0.57      0.22      0.32        18\n",
      "     Romance       0.32      0.61      0.42        51\n",
      "      Sci_Fi       0.67      0.50      0.57        16\n",
      "    Thriller       0.45      0.54      0.49        28\n",
      "         War       0.67      0.29      0.40        21\n",
      "     Western       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.42       299\n",
      "   macro avg       0.39      0.30      0.32       299\n",
      "weighted avg       0.43      0.42      0.41       299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#MLP classifier using tf-idf as data processing method\n",
    "#Classifier parameter: solver=adam, learning rate=0.001\n",
    "\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import warnings \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from pandas.core.frame import DataFrame  #need?\n",
    "\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def tf_idf(data_train, data_valid, data_test):\n",
    "    cv = CountVectorizer()\n",
    "    cv.fit(data_train)\n",
    "    word = cv.get_feature_names()\n",
    "    v = TfidfVectorizer()\n",
    "    train = v.fit_transform(data_train)\n",
    "    valid = v.transform(data_valid)\n",
    "    test = v.transform(data_test)\n",
    "    train_weight = train.toarray()\n",
    "    valid_weight = valid.toarray()\n",
    "    test_weight = test.toarray()\n",
    "    return train_weight, valid_weight, test_weight, word\n",
    "    \n",
    "\n",
    "def convert_to_usable_dataframe(weight, data_frame, word):\n",
    "    instance_count, word_count = weight.shape\n",
    "    for j in range(word_count):\n",
    "        temp = []\n",
    "        for i in range(instance_count):\n",
    "            temp.append(weight[i, j])\n",
    "        data_frame[word[j]] = temp\n",
    "    data_frame = data_frame.drop([\"tag\", \"movieId\", \"YTId\", \"year\", \"title\"], axis = 1)\n",
    "    return data_frame\n",
    "            \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#load data\n",
    "train_features = pd.read_csv(open(\"train_features.tsv\"), sep='\\t')\n",
    "train_labels = pd.read_csv(open(\"train_labels.tsv\"), sep='\\t')\n",
    "valid_features = pd.read_csv(open(\"valid_features.tsv\"), sep='\\t')\n",
    "valid_labels = pd.read_csv(open(\"valid_labels.tsv\"), sep='\\t')\n",
    "test_features = pd.read_csv(open(\"NEW_test_features.tsv\"), sep='\\t')\n",
    "\n",
    "#do tfidf, convert it to usable data\n",
    "tf_idf_weight_train, tf_idf_weight_valid, tf_idf_weight_test, allWords = tf_idf(train_features.iloc[:, 4], valid_features.iloc[:, 4], test_features.iloc[:, 4])\n",
    "\n",
    "#convert the dataframe to usable one\n",
    "new_train_features = convert_to_usable_dataframe(tf_idf_weight_train, train_features, allWords)\n",
    "new_valid_features = convert_to_usable_dataframe(tf_idf_weight_valid, valid_features, allWords)\n",
    "new_test_features = convert_to_usable_dataframe(tf_idf_weight_test, test_features, allWords)\n",
    "\n",
    "new_train_labels = train_labels.drop([\"movieId\"], axis = 1)\n",
    "new_valid_labels = valid_labels.drop([\"movieId\"], axis = 1)\n",
    "\n",
    "#mlp classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation = 'logistic' ,solver='adam', learning_rate_init=0.001, learning_rate = 'constant')\n",
    "mlp.fit(new_train_features, new_train_labels.values.ravel()) #convert to array to fit the dataframe\n",
    "labels_predict = mlp.predict(new_valid_features)\n",
    "\n",
    "print(classification_report(new_valid_labels, labels_predict))\n",
    "\n",
    "labels_predict_test = mlp.predict(new_test_features)  #for kaggle\n",
    "\n",
    "def output_csv(test_features, predict_test):\n",
    "    data_frame = test_features.iloc[:, 0]\n",
    "    temp = test_features\n",
    "    temp.rename(columns={'title':'genres'}, inplace = True)\n",
    "    temp_data_frame = temp.iloc[:, 1]\n",
    "    x, y = test_features.shape\n",
    "    for i in range(x):\n",
    "        temp_data_frame.iloc[i] = predict_test[i]\n",
    "    data = pd.concat([data_frame, temp_data_frame], axis=1)\n",
    "    \n",
    "    data.to_csv (r'/Users/liuyuting/2020 SM1 assignment/ML assignment/assignment 2/predict_test_labels_MLP.csv', index = False, header=True)\n",
    "\n",
    "output_csv(test_features, labels_predict_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Action       1.00      0.17      0.29         6\n",
      "   Adventure       0.00      0.00      0.00         2\n",
      "   Animation       0.50      0.33      0.40         3\n",
      "    Children       0.50      0.33      0.40         3\n",
      "      Comedy       0.41      0.61      0.49        38\n",
      "       Crime       0.00      0.00      0.00         5\n",
      " Documentary       0.46      0.72      0.57        18\n",
      "       Drama       0.54      0.44      0.49        43\n",
      "     Fantasy       0.71      0.28      0.40        18\n",
      "   Film_Noir       0.00      0.00      0.00         4\n",
      "      Horror       0.38      0.75      0.50         8\n",
      "     Musical       0.25      0.10      0.14        10\n",
      "     Mystery       0.67      0.11      0.19        18\n",
      "     Romance       0.34      0.47      0.40        51\n",
      "      Sci_Fi       0.62      0.62      0.62        16\n",
      "    Thriller       0.34      0.61      0.44        28\n",
      "         War       0.71      0.24      0.36        21\n",
      "     Western       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.43       299\n",
      "   macro avg       0.41      0.32      0.32       299\n",
      "weighted avg       0.46      0.43      0.40       299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#MLP classifier using one-hot as data processing method\n",
    "#Classifier parameter: solver=adam, learning rate=0.001\n",
    "\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import warnings \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from pandas.core.frame import DataFrame  #need?\n",
    "\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def all_different_tags(data_frame):\n",
    "    all_different_tags = []\n",
    "    tags_column = data_frame.iloc[:, 4]   #take out the tag column\n",
    "    for instance in tags_column:\n",
    "        for tag in instance.split(\",\"):\n",
    "            if tag not in all_different_tags:\n",
    "                all_different_tags.append(tag)\n",
    "    return all_different_tags\n",
    "    \n",
    "def one_hot_tag(data_frame, all_different_tags):\n",
    "    instance_count, feature_count = data_frame.shape\n",
    "    tags_column = data_frame.iloc[:, 4]\n",
    "    for tag in all_different_tags:\n",
    "        temp = []\n",
    "        for i in range(instance_count):\n",
    "            local_tags = tags_column[i].split(\",\")\n",
    "            if tag in local_tags:\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        data_frame[tag] = temp\n",
    "    data_frame = data_frame.drop([\"tag\"], axis = 1)\n",
    "    return data_frame\n",
    "            \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#load data\n",
    "train_features = pd.read_csv(open(\"train_features.tsv\"), sep='\\t')\n",
    "train_labels = pd.read_csv(open(\"train_labels.tsv\"), sep='\\t')\n",
    "valid_features = pd.read_csv(open(\"valid_features.tsv\"), sep='\\t')\n",
    "valid_labels = pd.read_csv(open(\"valid_labels.tsv\"), sep='\\t')\n",
    "test_features = pd.read_csv(open(\"NEW_test_features.tsv\"), sep='\\t')\n",
    "\n",
    "all_tags = all_different_tags(train_features)\n",
    "\n",
    "#convert the dataframe to usable one\n",
    "new_train_features = one_hot_tag(train_features, all_tags)\n",
    "new_train_features = new_train_features.drop([\"movieId\", \"YTId\", \"year\", \"title\"], axis = 1)\n",
    "\n",
    "new_valid_features = one_hot_tag(valid_features, all_tags)\n",
    "new_valid_features = new_valid_features.drop([\"movieId\", \"YTId\", \"year\", \"title\"], axis = 1)\n",
    "\n",
    "new_train_labels = train_labels.drop([\"movieId\"], axis = 1)\n",
    "new_valid_labels = valid_labels.drop([\"movieId\"], axis = 1)\n",
    "\n",
    "#mlp classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation = 'logistic' ,solver='adam', learning_rate_init=0.001, learning_rate = 'constant')\n",
    "mlp.fit(new_train_features, new_train_labels.values.ravel()) #convert to array to fit the dataframe\n",
    "labels_predict = mlp.predict(new_valid_features)\n",
    "\n",
    "print(classification_report(new_valid_labels, labels_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "train_features = pd.read_csv(open(\"train_features.tsv\"), sep='\\t')\n",
    "train_labels = pd.read_csv(open(\"train_labels.tsv\"), sep='\\t')\n",
    "valid_features = pd.read_csv(open(\"valid_features.tsv\"), sep='\\t')\n",
    "valid_labels = pd.read_csv(open(\"valid_labels.tsv\"), sep='\\t')\n",
    "test_features = pd.read_csv(open(\"NEW_test_features.tsv\"), sep='\\t')\n",
    "\n",
    "#do tfidf, convert it to usable data\n",
    "tf_idf_weight_train, tf_idf_weight_valid, tf_idf_weight_test, allWords = tf_idf(train_features.iloc[:, 4], valid_features.iloc[:, 4], test_features.iloc[:, 4])\n",
    "\n",
    "#convert the dataframe to usable one\n",
    "new_train_features = convert_to_usable_dataframe(tf_idf_weight_train, train_features, allWords)\n",
    "new_valid_features = convert_to_usable_dataframe(tf_idf_weight_valid, valid_features, allWords)\n",
    "new_test_features = convert_to_usable_dataframe(tf_idf_weight_test, test_features, allWords)\n",
    "\n",
    "new_train_labels = train_labels.drop([\"movieId\"], axis = 1)\n",
    "new_valid_labels = valid_labels.drop([\"movieId\"], axis = 1)\n",
    "\n",
    "class_labels = ['Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film_Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci_Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "\n",
    "def convert_to_num(data, class_labels):\n",
    "    temp = []\n",
    "    ins, col = data.shape\n",
    "    j = 0\n",
    "    while j < ins:\n",
    "        i = 0\n",
    "        while i < 18:\n",
    "            if data.iloc[j, 0] == class_labels[i]:\n",
    "                data.iloc[j, 0] = i+1\n",
    "            i = i+1\n",
    "        \n",
    "        j = j+1\n",
    "        \n",
    "    #data['num'] = temp\n",
    "    return data\n",
    "\n",
    "def convert_to_num2(predict, data, class_labels):\n",
    "    temp = []\n",
    "    ins = len(predict)\n",
    "    j = 0\n",
    "    while j < ins:\n",
    "        i = 0\n",
    "        while i < 18:\n",
    "            if predict[j] == class_labels[i]:\n",
    "                data.iloc[j] = i+1\n",
    "                #predict[j] = i+1\n",
    "            i = i+1\n",
    "        \n",
    "        j = j+1\n",
    "        \n",
    "    #data['num'] = temp\n",
    "    return data\n",
    "\n",
    "data1 = convert_to_num(new_valid_labels, class_labels)\n",
    "\n",
    "\n",
    "#mlp classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation = 'logistic' ,solver='adam', learning_rate_init=0.001, learning_rate = 'constant')\n",
    "mlp.fit(new_train_features, new_train_labels.values.ravel()) #convert to array to fit the dataframe\n",
    "labels_predict = mlp.predict(new_valid_features)\n",
    "\n",
    "temp_data = new_valid_features.iloc[:, 0]\n",
    "\n",
    "data2 = convert_to_num2(labels_predict, temp_data, class_labels) #predict\n",
    "\n",
    "\n",
    "data1.to_csv (r'/Users/liuyuting/2020 SM1 assignment/ML assignment/assignment 2/numerical_valid_labels_MLP.csv', index = False, header=True)\n",
    "data2.to_csv (r'/Users/liuyuting/2020 SM1 assignment/ML assignment/assignment 2/numerical_predict_valid_labels_MLP.csv', index = False, header=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
