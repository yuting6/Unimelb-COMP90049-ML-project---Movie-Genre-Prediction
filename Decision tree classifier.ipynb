{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Action       0.00      0.00      0.00         6\n",
      "   Adventure       0.17      0.50      0.25         2\n",
      "   Animation       0.00      0.00      0.00         3\n",
      "    Children       0.00      0.00      0.00         3\n",
      "      Comedy       0.25      0.21      0.23        38\n",
      "       Crime       0.08      0.20      0.12         5\n",
      " Documentary       0.54      0.39      0.45        18\n",
      "       Drama       0.27      0.33      0.29        43\n",
      "     Fantasy       0.23      0.17      0.19        18\n",
      "   Film_Noir       0.50      0.25      0.33         4\n",
      "      Horror       0.00      0.00      0.00         8\n",
      "     Musical       0.00      0.00      0.00        10\n",
      "     Mystery       0.00      0.00      0.00        18\n",
      "     Romance       0.26      0.24      0.24        51\n",
      "      Sci_Fi       0.26      0.38      0.31        16\n",
      "    Thriller       0.21      0.25      0.23        28\n",
      "         War       0.55      0.29      0.37        21\n",
      "     Western       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.22       299\n",
      "   macro avg       0.18      0.18      0.17       299\n",
      "weighted avg       0.24      0.22      0.22       299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision tree classifier using tf-idf as data processing method\n",
    "#Classifier parameter: Gini Impurity(default)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import warnings \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from pandas.core.frame import DataFrame  #need?\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def tf_idf(data_train, data_valid, data_test):\n",
    "    cv = CountVectorizer()\n",
    "    cv.fit(data_train)\n",
    "    word = cv.get_feature_names()\n",
    "    v = TfidfVectorizer()\n",
    "    train = v.fit_transform(data_train)\n",
    "    valid = v.transform(data_valid)\n",
    "    test = v.transform(data_test)\n",
    "    train_weight = train.toarray()\n",
    "    valid_weight = valid.toarray()\n",
    "    test_weight = test.toarray()\n",
    "    return train_weight, valid_weight, test_weight, word\n",
    "    \n",
    "\n",
    "def convert_to_usable_dataframe(weight, data_frame, word):\n",
    "    instance_count, word_count = weight.shape\n",
    "    for j in range(word_count):\n",
    "        temp = []\n",
    "        for i in range(instance_count):\n",
    "            temp.append(weight[i, j])\n",
    "        data_frame[word[j]] = temp\n",
    "    data_frame = data_frame.drop([\"tag\", \"movieId\", \"YTId\", \"year\", \"title\"], axis = 1)\n",
    "    return data_frame\n",
    "            \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#load data\n",
    "train_features = pd.read_csv(open(\"train_features.tsv\"), sep='\\t')\n",
    "train_labels = pd.read_csv(open(\"train_labels.tsv\"), sep='\\t')\n",
    "valid_features = pd.read_csv(open(\"valid_features.tsv\"), sep='\\t')\n",
    "valid_labels = pd.read_csv(open(\"valid_labels.tsv\"), sep='\\t')\n",
    "test_features = pd.read_csv(open(\"NEW_test_features.tsv\"), sep='\\t')\n",
    "\n",
    "#do tfidf, convert it to usable data\n",
    "tf_idf_weight_train, tf_idf_weight_valid, tf_idf_weight_test, allWords = tf_idf(train_features.iloc[:, 4], valid_features.iloc[:, 4], test_features.iloc[:, 4])\n",
    "\n",
    "#convert the dataframe to usable one\n",
    "new_train_features = convert_to_usable_dataframe(tf_idf_weight_train, train_features, allWords)\n",
    "new_valid_features = convert_to_usable_dataframe(tf_idf_weight_valid, valid_features, allWords)\n",
    "new_test_features = convert_to_usable_dataframe(tf_idf_weight_test, test_features, allWords)\n",
    "\n",
    "new_train_labels = train_labels.drop([\"movieId\"], axis = 1)\n",
    "new_valid_labels = valid_labels.drop([\"movieId\"], axis = 1)\n",
    "\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(new_train_features, new_train_labels.values.ravel())  #convert to array to fit the dataframe\n",
    "predict = dt.predict(new_valid_features)\n",
    "\n",
    "print(classification_report(new_valid_labels, predict))\n",
    "\n",
    "labels_predict_test = dt.predict(new_test_features) #for kaggle\n",
    "\n",
    "def output_csv(test_features, predict_test):\n",
    "    data_frame = test_features.iloc[:, 0]\n",
    "    temp = test_features\n",
    "    temp.rename(columns={'title':'genres'}, inplace = True)\n",
    "    temp_data_frame = temp.iloc[:, 1]\n",
    "    x, y = test_features.shape\n",
    "    for i in range(x):\n",
    "        temp_data_frame.iloc[i] = predict_test[i]\n",
    "    data = pd.concat([data_frame, temp_data_frame], axis=1)\n",
    "    \n",
    "    data.to_csv (r'/Users/liuyuting/2020 SM1 assignment/ML assignment/assignment 2/predict_test_labels_DT.csv', index = False, header=True)\n",
    "\n",
    "output_csv(test_features, labels_predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Action       0.00      0.00      0.00         6\n",
      "   Adventure       0.00      0.00      0.00         2\n",
      "   Animation       0.17      0.33      0.22         3\n",
      "    Children       0.00      0.00      0.00         3\n",
      "      Comedy       0.33      0.24      0.28        38\n",
      "       Crime       0.10      0.20      0.13         5\n",
      " Documentary       0.36      0.22      0.28        18\n",
      "       Drama       0.25      0.19      0.21        43\n",
      "     Fantasy       0.42      0.28      0.33        18\n",
      "   Film_Noir       0.00      0.00      0.00         4\n",
      "      Horror       0.12      0.12      0.12         8\n",
      "     Musical       0.10      0.10      0.10        10\n",
      "     Mystery       0.06      0.06      0.06        18\n",
      "     Romance       0.25      0.27      0.26        51\n",
      "      Sci_Fi       0.35      0.69      0.47        16\n",
      "    Thriller       0.21      0.32      0.26        28\n",
      "         War       0.44      0.19      0.27        21\n",
      "     Western       0.25      0.14      0.18         7\n",
      "\n",
      "    accuracy                           0.23       299\n",
      "   macro avg       0.19      0.19      0.18       299\n",
      "weighted avg       0.26      0.23      0.23       299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision tree classifier using tf-idf as data processing method\n",
    "#Classifier parameter: Entropy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import warnings \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from pandas.core.frame import DataFrame  #need?\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def tf_idf(data_train, data_valid, data_test):\n",
    "    cv = CountVectorizer()\n",
    "    cv.fit(data_train)\n",
    "    word = cv.get_feature_names()\n",
    "    v = TfidfVectorizer()\n",
    "    train = v.fit_transform(data_train)\n",
    "    valid = v.transform(data_valid)\n",
    "    test = v.transform(data_test)\n",
    "    train_weight = train.toarray()\n",
    "    valid_weight = valid.toarray()\n",
    "    test_weight = test.toarray()\n",
    "    return train_weight, valid_weight, test_weight, word\n",
    "    \n",
    "\n",
    "def convert_to_usable_dataframe(weight, data_frame, word):\n",
    "    instance_count, word_count = weight.shape\n",
    "    for j in range(word_count):\n",
    "        temp = []\n",
    "        for i in range(instance_count):\n",
    "            temp.append(weight[i, j])\n",
    "        data_frame[word[j]] = temp\n",
    "    data_frame = data_frame.drop([\"tag\", \"movieId\", \"YTId\", \"year\", \"title\"], axis = 1)\n",
    "    return data_frame\n",
    "            \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#load data\n",
    "train_features = pd.read_csv(open(\"train_features.tsv\"), sep='\\t')\n",
    "train_labels = pd.read_csv(open(\"train_labels.tsv\"), sep='\\t')\n",
    "valid_features = pd.read_csv(open(\"valid_features.tsv\"), sep='\\t')\n",
    "valid_labels = pd.read_csv(open(\"valid_labels.tsv\"), sep='\\t')\n",
    "test_features = pd.read_csv(open(\"NEW_test_features.tsv\"), sep='\\t')\n",
    "\n",
    "#do tfidf, convert it to usable data\n",
    "tf_idf_weight_train, tf_idf_weight_valid, tf_idf_weight_test, allWords = tf_idf(train_features.iloc[:, 4], valid_features.iloc[:, 4], test_features.iloc[:, 4])\n",
    "\n",
    "#convert the dataframe to usable one\n",
    "new_train_features = convert_to_usable_dataframe(tf_idf_weight_train, train_features, allWords)\n",
    "new_valid_features = convert_to_usable_dataframe(tf_idf_weight_valid, valid_features, allWords)\n",
    "new_test_features = convert_to_usable_dataframe(tf_idf_weight_test, test_features, allWords)\n",
    "\n",
    "new_train_labels = train_labels.drop([\"movieId\"], axis = 1)\n",
    "new_valid_labels = valid_labels.drop([\"movieId\"], axis = 1)\n",
    "\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion='entropy')\n",
    "dt.fit(new_train_features, new_train_labels.values.ravel())  #convert to array to fit the dataframe\n",
    "predict = dt.predict(new_valid_features)\n",
    "\n",
    "print(classification_report(new_valid_labels, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Action       0.00      0.00      0.00         6\n",
      "   Adventure       0.00      0.00      0.00         2\n",
      "   Animation       0.00      0.00      0.00         3\n",
      "    Children       0.00      0.00      0.00         3\n",
      "      Comedy       0.30      0.29      0.29        38\n",
      "       Crime       0.18      0.40      0.25         5\n",
      " Documentary       0.46      0.33      0.39        18\n",
      "       Drama       0.22      0.21      0.21        43\n",
      "     Fantasy       0.17      0.17      0.17        18\n",
      "   Film_Noir       0.00      0.00      0.00         4\n",
      "      Horror       0.10      0.12      0.11         8\n",
      "     Musical       0.00      0.00      0.00        10\n",
      "     Mystery       0.12      0.11      0.12        18\n",
      "     Romance       0.22      0.20      0.21        51\n",
      "      Sci_Fi       0.33      0.56      0.42        16\n",
      "    Thriller       0.26      0.32      0.29        28\n",
      "         War       0.43      0.29      0.34        21\n",
      "     Western       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.23       299\n",
      "   macro avg       0.16      0.17      0.16       299\n",
      "weighted avg       0.23      0.23      0.22       299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision tree classifier using one-hot as data processing method\n",
    "#Classifier parameter: Gini Impurity(default)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import warnings \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from pandas.core.frame import DataFrame  #need?\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def all_different_tags(data_frame):\n",
    "    all_different_tags = []\n",
    "    tags_column = data_frame.iloc[:, 4]   #take out the tag column\n",
    "    for instance in tags_column:\n",
    "        for tag in instance.split(\",\"):\n",
    "            if tag not in all_different_tags:\n",
    "                all_different_tags.append(tag)\n",
    "    return all_different_tags\n",
    "    \n",
    "def one_hot_tag(data_frame, all_different_tags):\n",
    "    instance_count, feature_count = data_frame.shape\n",
    "    tags_column = data_frame.iloc[:, 4]\n",
    "    for tag in all_different_tags:\n",
    "        temp = []\n",
    "        for i in range(instance_count):\n",
    "            local_tags = tags_column[i].split(\",\")\n",
    "            if tag in local_tags:\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        data_frame[tag] = temp\n",
    "    data_frame = data_frame.drop([\"tag\"], axis = 1)\n",
    "    return data_frame\n",
    "            \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#load data\n",
    "train_features = pd.read_csv(open(\"train_features.tsv\"), sep='\\t')\n",
    "train_labels = pd.read_csv(open(\"train_labels.tsv\"), sep='\\t')\n",
    "valid_features = pd.read_csv(open(\"valid_features.tsv\"), sep='\\t')\n",
    "valid_labels = pd.read_csv(open(\"valid_labels.tsv\"), sep='\\t')\n",
    "test_features = pd.read_csv(open(\"NEW_test_features.tsv\"), sep='\\t')\n",
    "\n",
    "all_tags = all_different_tags(train_features)\n",
    "\n",
    "#convert the dataframe to usable one\n",
    "new_train_features = one_hot_tag(train_features, all_tags)\n",
    "new_train_features = new_train_features.drop([\"movieId\", \"YTId\", \"year\", \"title\"], axis = 1)\n",
    "\n",
    "new_valid_features = one_hot_tag(valid_features, all_tags)\n",
    "new_valid_features = new_valid_features.drop([\"movieId\", \"YTId\", \"year\", \"title\"], axis = 1)\n",
    "\n",
    "new_train_labels = train_labels.drop([\"movieId\"], axis = 1)\n",
    "new_valid_labels = valid_labels.drop([\"movieId\"], axis = 1)\n",
    "\n",
    "\n",
    "dt = DecisionTreeClassifier() #default is gini\n",
    "dt.fit(new_train_features, new_train_labels.values.ravel())  #convert to array to fit the dataframe\n",
    "predict = dt.predict(new_valid_features)\n",
    "\n",
    "print(classification_report(new_valid_labels, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Action       0.00      0.00      0.00         6\n",
      "   Adventure       0.00      0.00      0.00         2\n",
      "   Animation       0.00      0.00      0.00         3\n",
      "    Children       0.00      0.00      0.00         3\n",
      "      Comedy       0.27      0.29      0.28        38\n",
      "       Crime       0.00      0.00      0.00         5\n",
      " Documentary       0.31      0.22      0.26        18\n",
      "       Drama       0.27      0.21      0.24        43\n",
      "     Fantasy       0.21      0.22      0.22        18\n",
      "   Film_Noir       0.00      0.00      0.00         4\n",
      "      Horror       0.08      0.12      0.10         8\n",
      "     Musical       0.09      0.10      0.10        10\n",
      "     Mystery       0.06      0.06      0.06        18\n",
      "     Romance       0.21      0.14      0.16        51\n",
      "      Sci_Fi       0.26      0.56      0.35        16\n",
      "    Thriller       0.15      0.21      0.18        28\n",
      "         War       0.19      0.14      0.16        21\n",
      "     Western       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.19       299\n",
      "   macro avg       0.12      0.13      0.12       299\n",
      "weighted avg       0.19      0.19      0.18       299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision tree classifier using one-hot as data processing method\n",
    "#Classifier parameter: Entropy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import warnings \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from pandas.core.frame import DataFrame  #need?\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def all_different_tags(data_frame):\n",
    "    all_different_tags = []\n",
    "    tags_column = data_frame.iloc[:, 4]   #take out the tag column\n",
    "    for instance in tags_column:\n",
    "        for tag in instance.split(\",\"):\n",
    "            if tag not in all_different_tags:\n",
    "                all_different_tags.append(tag)\n",
    "    return all_different_tags\n",
    "    \n",
    "def one_hot_tag(data_frame, all_different_tags):\n",
    "    instance_count, feature_count = data_frame.shape\n",
    "    tags_column = data_frame.iloc[:, 4]\n",
    "    for tag in all_different_tags:\n",
    "        temp = []\n",
    "        for i in range(instance_count):\n",
    "            local_tags = tags_column[i].split(\",\")\n",
    "            if tag in local_tags:\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        data_frame[tag] = temp\n",
    "    data_frame = data_frame.drop([\"tag\"], axis = 1)\n",
    "    return data_frame\n",
    "            \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#load data\n",
    "train_features = pd.read_csv(open(\"train_features.tsv\"), sep='\\t')\n",
    "train_labels = pd.read_csv(open(\"train_labels.tsv\"), sep='\\t')\n",
    "valid_features = pd.read_csv(open(\"valid_features.tsv\"), sep='\\t')\n",
    "valid_labels = pd.read_csv(open(\"valid_labels.tsv\"), sep='\\t')\n",
    "test_features = pd.read_csv(open(\"NEW_test_features.tsv\"), sep='\\t')\n",
    "\n",
    "all_tags = all_different_tags(train_features)\n",
    "\n",
    "#convert the dataframe to usable one\n",
    "new_train_features = one_hot_tag(train_features, all_tags)\n",
    "new_train_features = new_train_features.drop([\"movieId\", \"YTId\", \"year\", \"title\"], axis = 1)\n",
    "\n",
    "new_valid_features = one_hot_tag(valid_features, all_tags)\n",
    "new_valid_features = new_valid_features.drop([\"movieId\", \"YTId\", \"year\", \"title\"], axis = 1)\n",
    "\n",
    "new_train_labels = train_labels.drop([\"movieId\"], axis = 1)\n",
    "new_valid_labels = valid_labels.drop([\"movieId\"], axis = 1)\n",
    "\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion='entropy') #default is gini\n",
    "dt.fit(new_train_features, new_train_labels.values.ravel())  #convert to array to fit the dataframe\n",
    "predict = dt.predict(new_valid_features)\n",
    "\n",
    "print(classification_report(new_valid_labels, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "train_features = pd.read_csv(open(\"train_features.tsv\"), sep='\\t')\n",
    "train_labels = pd.read_csv(open(\"train_labels.tsv\"), sep='\\t')\n",
    "valid_features = pd.read_csv(open(\"valid_features.tsv\"), sep='\\t')\n",
    "valid_labels = pd.read_csv(open(\"valid_labels.tsv\"), sep='\\t')\n",
    "test_features = pd.read_csv(open(\"NEW_test_features.tsv\"), sep='\\t')\n",
    "\n",
    "#do tfidf, convert it to usable data\n",
    "tf_idf_weight_train, tf_idf_weight_valid, tf_idf_weight_test, allWords = tf_idf(train_features.iloc[:, 4], valid_features.iloc[:, 4], test_features.iloc[:, 4])\n",
    "\n",
    "#convert the dataframe to usable one\n",
    "new_train_features = convert_to_usable_dataframe(tf_idf_weight_train, train_features, allWords)\n",
    "new_valid_features = convert_to_usable_dataframe(tf_idf_weight_valid, valid_features, allWords)\n",
    "new_test_features = convert_to_usable_dataframe(tf_idf_weight_test, test_features, allWords)\n",
    "\n",
    "new_train_labels = train_labels.drop([\"movieId\"], axis = 1)\n",
    "new_valid_labels = valid_labels.drop([\"movieId\"], axis = 1)\n",
    "\n",
    "class_labels = ['Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film_Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci_Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "\n",
    "def convert_to_num(data, class_labels):\n",
    "    temp = []\n",
    "    ins, col = data.shape\n",
    "    j = 0\n",
    "    while j < ins:\n",
    "        i = 0\n",
    "        while i < 18:\n",
    "            if data.iloc[j, 0] == class_labels[i]:\n",
    "                data.iloc[j, 0] = i+1\n",
    "            i = i+1\n",
    "        \n",
    "        j = j+1\n",
    "        \n",
    "    #data['num'] = temp\n",
    "    return data\n",
    "\n",
    "def convert_to_num2(predict, data, class_labels):\n",
    "    temp = []\n",
    "    ins = len(predict)\n",
    "    j = 0\n",
    "    while j < ins:\n",
    "        i = 0\n",
    "        while i < 18:\n",
    "            if predict[j] == class_labels[i]:\n",
    "                data.iloc[j] = i+1\n",
    "                #predict[j] = i+1\n",
    "            i = i+1\n",
    "        \n",
    "        j = j+1\n",
    "        \n",
    "    #data['num'] = temp\n",
    "    return data\n",
    "\n",
    "data1 = convert_to_num(new_valid_labels, class_labels)\n",
    "\n",
    "\n",
    "#mlp classifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(new_train_features, new_train_labels.values.ravel())  #convert to array to fit the dataframe\n",
    "labels_predict = dt.predict(new_valid_features)\n",
    "\n",
    "temp_data = new_valid_features.iloc[:, 0]\n",
    "\n",
    "data2 = convert_to_num2(labels_predict, temp_data, class_labels) #predict\n",
    "\n",
    "\n",
    "data1.to_csv (r'/Users/liuyuting/2020 SM1 assignment/ML assignment/assignment 2/numerical_valid_labels_DT.csv', index = False, header=True)\n",
    "data2.to_csv (r'/Users/liuyuting/2020 SM1 assignment/ML assignment/assignment 2/numerical_predict_valid_labels_DT.csv', index = False, header=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
